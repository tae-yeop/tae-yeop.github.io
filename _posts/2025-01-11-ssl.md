---
title:  "Self-Supervised Learning"
excerpt:  "자기지도 학습 정리"
categories: 
- Self-Supervised Learning

tags:
- Self-Supervised Learning
 
toc_label: TOC
toc: true
toc_sticky: true
 
date: 2025-01-11
---

- 일종의 Representation Learning의 하위 개념이라고 생각하면 됨
- 활용 용도는 라벨링하지 않는 대규모 데이터셋에 Pretraining 시킨 뒤에 Donwstream task에 finetuning하는식으로 할 수 있음
- 혹은 임베딩을 뽑아내는 Feature Extractor로도 사용할 수 있음
- 라벨링이 지니는 정보가 적은 경우도 있음
- Supervised learning으로 학습하면 => 해당 Task에는 잘하지만 범용적으로 활동을 떨어짐



- 계열


## [BYOL](https://arxiv.org/abs/2006.07733)
- 기존의 SSL은 negative pair가 필요하다는 한계점이 있었다. 
- 특히 SSL에서 SOTA 성능을 달성한 Contrastive learning (CL)은 negative sample을 많이 두어서 성능 향상이 보장되었다. 게다가 negative sample이 제대로 확보되지 않으면 collapsed representation이라 불리는 문제가 생길 수 있다. BYOL에선negative pair를 요구하지 않는다. 대신 아키텍처는 같지만 다른 parameter를 쓰는 모델 2개를 사용한다. 

두 개의 모델 : online model, target model

- target model( $\xi$)를 $\theta$의 MVA로 두도록 한다.
- oneline model은 target model parameter $\xi$에서 학습하여 $\theta$를 업데이트한다.

![Image](https://github.com/user-attachments/assets/63ede995-dd9e-453a-842c-4ea8a4804c91)

![Image](https://github.com/user-attachments/assets/49fc0a9e-9e9d-45b1-8134-a56e5cbd4a92)

$$
\mathcal{L}_{\theta, \xi} := ||\bar{q}_{\theta}(z_{\theta}) - \bar{z'}_{\xi}||^2_2
$$

$$
\bar{q_\theta}(z_\theta) := q_{\theta}(z_{\theta}) / ||q_{\theta}(z_{\theta})||_2 \\

\bar{z}'_{\xi} := \frac{z'_{\xi}}{||z'_{\xi}||_2}
$$



## [I-JEPA](https://arxiv.org/abs/2301.08243)
- (23.1)
- SSL 분야를 선도하는 얀 르쿤 교수님이 트위터에서 많이 홍보한 연구
- 이미지에 대한 representation을 좋은 임베딩을 얻고자 함

![Untitled](https://github.com/user-attachments/assets/3d6937b6-0859-489f-9967-2bff31a35215)

- single context block을 사용해서 다양한 타겟 블록을 예측한다
- context encoder : ViT로써 visible context patches만 처리함
- The predictor : narrow ViT로써 positional tokens을 조건으로 받고 encoder 결과물을 받아서 해당 위치의 타겟블록 representation을 예측함
    - target representations은 target-encoder의 아웃풋에 대응된다
- target encoder : context encoder weights로 EMA로 업데이트된다

- 임베딩을 잘 학습했는데 linear probing을 해봄
- linear probing은 쉽게 말해 linear layer를 헤드에 달아서 classification task를 얼마나 잘 수 수행하는지 살펴보는 것



## [DoRA](https://arxiv.org/abs/2310.08584)
- 23.12 (ICRL 2024 Oral)



# Multi-Modal

## CLIP
- 웹크롤링해서 얻은 자연어 텍스트와 이미지를 사용 (4억개의 이미지-텍스트)
- class label이 없어서 분류 문제로 학습하는게 아님
- N개의 이미지들과 N개의 텍스트들 사이의 연결관계를 찾는 문제로 학습
- ImageNet을 보지 않고도 (ZeroShot으로) 견줄 수 있는 성능을 달성
- 다양한 이미지 데이터셋에도 ImageNet으로 학습한 모델보다 성능이 뛰어남
- 이미지 한장이 주어지면 32,768개의 샘플 텍스트 정보에서 어느게 짝이 맞는지 맞추도록 학습
- 이를 위해선 이미지내의 비주얼 컨셉을 인식할 수 있어야 하고 이를 이름과 연관 지을 수 있는 능력이 필요
- 이미지 인코더와 텍스트 인코더
    - 모두 Transformer
    - 256개의 V100 GPU로 12일간 학습


![Image](https://github.com/user-attachments/assets/2292e0f3-19b4-40f8-80aa-7064b55a0d02)

![Image](https://github.com/user-attachments/assets/d9c70247-2a79-4924-a8c9-f73fa212eedf)

![Image](https://github.com/user-attachments/assets/e3aac2b9-b229-4fcd-889e-8a1397c88053)

# 활용
- 그래서 실제로 어떻게 활용할 수 있는지가 중요
- 연구 논문용으로는 뭐 이리 볶고 저리 볶고 할 수 있겠지만 서비스 개발로 연결지을 만한 요소가 있을까?

## [Object Detection](https://arxiv.org/abs/2410.07442)
- 24년도 10월
- 실제 SSL을 한 백본을 Detection에 파인튜닝했을 때 스크래치 대비 성능 향상이 있음을 보여줌 (테이블4 참조)

- [Are Large-scale Datasets Necessary for Self-Supervised Pre-training?](https://arxiv.org/pdf/2112.10740)
- 여기서도 Random Init 대비 SSL을 적용한게 성능이 더 좋다고 리포트함
- 